{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implement a complete RAG system that starts with a YouTube URL, automatically transcribes it using Whisper, and then uses a retrieval-augmented generation pipeline to answer questions based on the video’s content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"] = \"TRUE\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup Your Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()  # Loads variables from .env\n",
    "\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "PINECONE_API_KEY = os.getenv(\"PINECONE_API_KEY\")\n",
    "PINECONE_API_ENV = os.getenv(\"PINECONE_API_ENV\")\n",
    "INDEX_NAME = os.getenv(\"INDEX_NAME\", \"youtube-transcripts\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download Audio from a YouTube URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Audio downloaded to: d:\\Work\\Jupyter projects\\Projects\\RAG-Applications\\Youtube Transcript RAG\\audio.mp4\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pytubefix import YouTube\n",
    "import whisper\n",
    "\n",
    "# Download audio from YouTube using pytubefix\n",
    "youtube_url = \"https://www.youtube.com/watch?v=HISRUrJsD08\"\n",
    "yt = YouTube(youtube_url)\n",
    "audio_stream = yt.streams.filter(only_audio=True).first()\n",
    "audio_file = audio_stream.download(filename=\"audio.mp4\")\n",
    "print(\"Audio downloaded to:\", audio_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transcribe the Audio Using Whisper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded transcription from transcript1.txt\n",
      "Transcript snippet:  AI agents is the biggest opportunity of 25. AI agents When you must be seeing it everywhere on social media, in news and in the startup space as well. Hi everyone, I'm Ishan Sharma and if you want to\n"
     ]
    }
   ],
   "source": [
    "# Define the transcription file name\n",
    "transcription_filename = \"transcript1.txt\"\n",
    "\n",
    "# If transcription file exists, load it; otherwise, transcribe and save it.\n",
    "if os.path.exists(transcription_filename):\n",
    "    with open(transcription_filename, \"r\", encoding=\"utf-8\") as file:\n",
    "        transcript = file.read()\n",
    "    print(\"Loaded transcription from\", transcription_filename)\n",
    "else:\n",
    "    # Load the Whisper model\n",
    "    whisper_model = whisper.load_model(\"base\")\n",
    "    # Transcribe the downloaded audio file\n",
    "    result = whisper_model.transcribe(audio_file)\n",
    "    transcript = result[\"text\"]\n",
    "    # Save the transcription to a text file\n",
    "    with open(transcription_filename, \"w\", encoding=\"utf-8\") as file:\n",
    "        file.write(transcript)\n",
    "    print(\"Transcription generated and saved to\", transcription_filename)\n",
    "\n",
    "# Print a snippet of the transcript\n",
    "print(\"Transcript snippet:\", transcript[:200])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split the Transcript into Chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of chunks: 17\n",
      "Sample chunk: AI agents is the biggest opportunity of 25. AI agents When you must be seeing it everywhere on social media, in news and in the startup space as well.\n"
     ]
    }
   ],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "# Adjust these parameters based on your transcript size and token limits\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "chunks = text_splitter.split_text(transcript)\n",
    "\n",
    "print(f\"Number of chunks: {len(chunks)}\")\n",
    "print(\"Sample chunk:\", chunks[0][:150])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Embeddings and Build a Vector Store"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Option A: Using FAISS (Local In-Memory Store)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rohan\\AppData\\Local\\Temp\\ipykernel_24080\\275497326.py:5: LangChainDeprecationWarning: The class `OpenAIEmbeddings` was deprecated in LangChain 0.0.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import OpenAIEmbeddings``.\n",
      "  embeddings = OpenAIEmbeddings(openai_api_key=OPENAI_API_KEY)\n"
     ]
    }
   ],
   "source": [
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "\n",
    "# Create embeddings object with your OpenAI API key\n",
    "embeddings = OpenAIEmbeddings(openai_api_key=OPENAI_API_KEY)\n",
    "\n",
    "# Build the FAISS vector store from text chunks\n",
    "vectorstore = FAISS.from_texts(chunks, embeddings)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Option B: Using Pinecone (Production-Ready)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pinecone import Pinecone, ServerlessSpec\n",
    "from langchain.vectorstores import Pinecone as LC_Pinecone\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "\n",
    "# Initialize the Pinecone client using the new interface\n",
    "pc = Pinecone(api_key=PINECONE_API_KEY)\n",
    "INDEX_NAME = \"test-yt-index\" \n",
    "\n",
    "# Optionally, check if the index exists and create it if not.\n",
    "# (Make sure the dimension matches your embeddings—in this example, 1536 for OpenAI)\n",
    "existing_indexes = pc.list_indexes().names()\n",
    "if INDEX_NAME not in existing_indexes:\n",
    "    pc.create_index(\n",
    "        name=INDEX_NAME,\n",
    "        dimension=1536,\n",
    "        metric=\"euclidean\",\n",
    "        spec=ServerlessSpec(cloud=\"aws\", region=PINECONE_API_ENV)\n",
    "    )\n",
    "    print(f\"Index '{INDEX_NAME}' created.\")\n",
    "else:\n",
    "    print(f\"Index '{INDEX_NAME}' already exists.\")\n",
    "\n",
    "# Create an embeddings object with your OpenAI API key\n",
    "embeddings = OpenAIEmbeddings(openai_api_key=OPENAI_API_KEY)\n",
    "\n",
    "# Assume 'chunks' is your list of text chunks.\n",
    "# Build the Pinecone vector store from text chunks using LangChain's wrapper.\n",
    "vectorstore = LC_Pinecone.from_texts(chunks, embeddings, index_name=INDEX_NAME)\n",
    "\n",
    "print(\"Pinecone vector store created successfully.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieve Relevant Context for a Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieved context:\n",
      " you start solving those. Figure out where is the majority of the money going by businesses. I have made a separate video which goes in depth and talks about the 15 top business ideas for AI agents in 2025. So check that if you are curious to learn more about this. That's all from me today. I hope you learned a thing or two. Let me know if you have any questions below in the comment section and I'll see you in the next video. The description will have some learning resources so check those out if you're interested. There's a report that Google published which is on AI agents so read that if you're curious and I'll see you in the next one. Bye.\n",
      "spending their money on hiring. They might be spending their money on operations, on finances, accounting, legal and a million other things. Figure out what are those tools which are these companies currently working with. And if you can build a AI agent version of those tools of those SaaS companies. This is from a recent Y Combinator video in which we talked about the best thing you can do is just to look at the best performing SaaS companies today and start building AI agent versions of those in which the AI agent is able to do all the things faster and saves a lot of time as well. And since there is no human intervention it is able to do it for cheaper as well. So just look at all of those SaaS companies start building those tools, those AI agents for those particular problems and you start solving those. Figure out where is the majority of the money going by businesses. I have made a separate video which goes in depth and talks about the 15 top business ideas for AI agents in\n",
      "make those changes and then send you another email asking you if the current script is good to go or not. And once you give a green light to that then it goes ahead and generates the audio from that, generates the video from that. But this is essentially what a N8N workflow would look like for creating AI agents from scratch. That is all that you need to learn to get started. Check out the deep learning AI course by crew AI, by land chain. There are other tools as well that you can use but just in general be curious. At the end of the day that is what you need to have. And lastly let's talk about the biggest business opportunities in the field of AI agents. The best way to think about this is imagine all of the companies and where do they spend most of their money on? They might be spending their money on hiring. They might be spending their money on operations, on finances, accounting, legal and a million other things. Figure out what are those tools which are these companies\n"
     ]
    }
   ],
   "source": [
    "query = \"Ideas to make money using AI agents?\"\n",
    "retrieved_docs = vectorstore.similarity_search(query, k=3)\n",
    "\n",
    "# Combine the retrieved document chunks into one context string\n",
    "context = \"\\n\".join([doc.page_content for doc in retrieved_docs])\n",
    "print(\"Retrieved context:\\n\", context)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build the Prompt and Execute the RAG Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final response: Some ideas to make money using AI agents include creating AI agent versions of popular SaaS tools, offering AI agent services for tasks like data analysis and customer service, developing AI agents for specific industries or business needs, and providing consulting services for businesses looking to implement AI agents.\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "# Define a prompt template that uses context and question\n",
    "template = \"\"\"Answer the question based on the context below.\n",
    "Context: {context}\n",
    "Question: {question}\n",
    "If you cannot answer, reply \"I don't know\".\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(template=template, input_variables=[\"context\", \"question\"])\n",
    "\n",
    "# Initialize the model (as done in Step 1) if not already done\n",
    "model = ChatOpenAI(model_name=\"gpt-3.5-turbo\", openai_api_key=OPENAI_API_KEY)\n",
    "\n",
    "# Create the chain to link the prompt with the model\n",
    "chain = LLMChain(llm=model, prompt=prompt)\n",
    "\n",
    "# Execute the chain\n",
    "response = chain.run(context=context, question=query)\n",
    "print(\"Final response:\", response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
